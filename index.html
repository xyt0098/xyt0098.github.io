<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yitao Xu</title>
  
  <meta name="author" content="Yitao Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåè</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yitao Xu (Âæê‰∏ÄÊ∂õ)</name>
              </p>
              <p>Welcome to my homepage! I am currently a 2nd year PhD student at <a href="https://www.epfl.ch/en/">√âcole polytechnique f√©d√©rale de Lausanne (EPFL)</a> in the <a href="https://www.epfl.ch/education/phd/edic-computer-and-communication-sciences/">EDIC</a> program. Before that, I was a master's student at <a href="https://www.kth.se/en/studies/master/machine-learning/">KTH Royal Institute of Technology</a>, majoring in Machine Learning. In 2022 Fall and 2023 Spring, I was an exchange master's student in Computer Science at EPFL. 
              </p>
              <p>
                I got my B.Eng degree in Computer Science and Technology at <a href="https://ev.buaa.edu.cn/">Beihang University (BUAA)</a>. I worked as a research student at <a href="https://xlliu-beihang.github.io/">State Key Laboratory of Software Development Environment (NLSDE)</a>, advised by <a href="https://xlliu-beihang.github.io/">Prof.Xianglong Liu</a>, and I also finished my bachelor's thesis project focusing on rectifying texture bias exposed in deep neural network there. After graduating from BUAA, I became a Machine Learning Intern at <a href="https://www.didiglobal.com/science/ailabs">DiDi AI Labs</a>, where I was led by <a href="https://chezhengping.xyz/">Dr. Zhengping Che</a> and <a href="https://scholar.google.com/citations?user=IirM9zMAAAAJ&hl=en-en">Prof.Jian Tang</a>. Beginning in 12.2020, I spent a wonderful winter at <a href="https://brain.tsinghua.edu.cn/en/index.htm">Tsinghua Laboratory of Brain and Intelligence (THBI)</a> under the supervision of <a href="https://brain.tsinghua.edu.cn/en/info/1010/1010.htm">Prof.Jia Liu</a>, studying intuitive physics engine and stability inference with convolutional neural networks. 
              </p>
              <p style="text-align:center">
                <a href="mailto:study0098@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_YitaoXu.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/yitao-xu-b016891b2/">Linkedin</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=jvCvNPQAAAAJ&hl=en-en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/study0098">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <th style="text-align:center;"><heading>Research</heading></th>
            </tr>
            <tr>
              <!-- <td style="padding:20px;width:100%;vertical-align:middle"> -->
              <td>
                <p>
                  I'm interested in Computer Vision and Machine Learning. Particularly, I focus on:
                  <ul>
                    <li>Neural cellular automata and self-organizing systems</li>
                    <li>Interpretability of adversarial attacks and adversarial robustness</li>
                    <li>Different cognition biases between humans and deep-learning based computer vision models</li>
                  </ul>
                  I believe studying bio-inspired models and investigating the difference between humans and machines can help us achieve silicon-based artificial human intelligence!
                </p>
              </td>
              <!-- </td> -->
            </tr>
          </tbody>
        </table>
        
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <th colspan="2" style="text-align:center;"><heading>Publications</heading><br><span style="color:gray;">"*" means equal contribution</span></th>
          
          <tr onmouseout="adanca_stop()" onmouseover="adanca_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='adanca_image'>
                  <img src='images/adanca_after.png' width="160"></div>
                <img src='images/adanca_before.png' width="160">
              </div>
              <script type="text/javascript">
                function adanca_start() {
                  document.getElementById('adanca_image').style.opacity = "1";
                }
        
                function adanca_stop() {
                  document.getElementById('adanca_image').style.opacity = "0";
                }
                adanca_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2406.08298">
                <papertitle>AdaNCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer</papertitle>
              </a>
              <br>
              <strong>Yitao Xu</strong>, 
              <a href="https://sites.google.com/view/tong-zhang">Tong Zhang</a>,
              <a href="https://people.epfl.ch/sabine.susstrunk">Sabine S√ºsstrunk</a>
              <br>
              <em>NeurIPS</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2406.08298">paper</a>
              /
              <a href="https://xyt0098.github.io/">code (Coming Soon!)</a>
              <p></p>
              <p>
                We propose AdaNCA, inserting NCA into ViTs as plug-and-play adaptors for enhancing their robustness. We develop a unified perspective of NCA and ViT in terms of token interaction learning. Our work takes the first step to scale NCA up to solve large-scale computer vision problems, and proves that NCA can be practically utilized to improve the robustness of current vision transformer models. 
              </p>
            </td>
          </tr>		
          
          <tr onmouseout="meshnca_stop()" onmouseover="meshnca_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='meshnca_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/meshnca.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/meshnca.png' width="160">
              </div>
              <script type="text/javascript">
                function meshnca_start() {
                  document.getElementById('meshnca_image').style.opacity = "1";
                }

                function meshnca_stop() {
                  document.getElementById('meshnca_image').style.opacity = "0";
                }
                meshnca_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2311.02820">
                <papertitle>Mesh Neural Cellular Automata</papertitle>
              </a>
              <br>
              <a href="https://pajouheshgar.github.io/">Ehsan Pajouheshgar*</a>,
              <strong>Yitao Xu*</strong>,
              <a href="https://scholar.google.ch/citations?user=A_HbzQMAAAAJ&hl=en/">Alexander Mordvintsev</a>,
              <a href="https://scholar.google.se/citations?user=x5sfH5MAAAAJ&hl=en/">Eyvind Niklasson</a>,
              <a href="https://sites.google.com/view/tong-zhang">Tong Zhang</a>,
							<a href="https://people.epfl.ch/sabine.susstrunk">Sabine S√ºsstrunk</a>
              <br>
              <em>SIGGRAPH</em>, 2024
              <br>
              <a href="https://meshnca.github.io/">project page</a>
              /
              <a href="https://arxiv.org/pdf/2311.02820">arXiv</a>
              /
              <a href="https://github.com/IVRL/MeshNCA">code</a>
              <p></p>
              <p>
                MeshNCA is a comprehensive framework for 3D texture synthesis. It is compatible with image or text targets, and enjoys various test-time properties such as texture density control, grafting, and mesh generalization. Play with our <a href="https://meshnca.github.io/">demo</a>!
                </p>
              <p>
              </p>
            </td>
          </tr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="noisenca_stop()" onmouseover="noisenca_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='noisenca_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/noisenca.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/noisenca.png' width="160">
                </div>
                <script type="text/javascript">
                  function noisenca_start() {
                    document.getElementById('noisenca_image').style.opacity = "1";
                  }
  
                  function noisenca_stop() {
                    document.getElementById('noisenca_image').style.opacity = "0";
                  }
                  noisenca_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2404.06279">
                  <papertitle>NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural Cellular Automata</papertitle>
                </a>
                <br>
                <a href="https://pajouheshgar.github.io/">Ehsan Pajouheshgar</a>,
                <strong>Yitao Xu</strong>,
                <a href="https://people.epfl.ch/sabine.susstrunk">Sabine S√ºsstrunk</a>
                <br>
                <em>ALife</em>, 2024 <span style="color: red;"><strong> (Best Student Paper Award)</strong></span>
                <br>
                <a href="https://noisenca.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2404.06279">arXiv</a>
                /
                <a href="https://noisenca.github.io/">code (Coming Soon!)</a>
                <p></p>
                <p>
                  We examine the behaviors of NCA at the spatio-temporal limit and find it struggling to generate correct patterns. We propose a simple yet effective solution by initializing the seeds with noises. The increased spatio-temporal continuity enables several test-time controls, including anisotropic scaling, multi-scale pattern formation, and continuous speed adjustment. Play with our <a href="https://noisenca.github.io/">demo</a>!
                  </p>
                <p>
                </p>
              </td>
            </tr>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr onmouseout="emergent_dynamics_nca_stop()" onmouseover="emergent_dynamics_nca_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='emergent_dynamics_nca_image'><video  width=100% height=100% muted autoplay loop>
                    <source src="images/emergent_dynamics_nca.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                    </video></div>
                    <img src='images/emergent_dynamics_nca.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function emergent_dynamics_nca_start() {
                      document.getElementById('emergent_dynamics_nca_image').style.opacity = "1";
                    }
    
                    function emergent_dynamics_nca_stop() {
                      document.getElementById('emergent_dynamics_nca_image').style.opacity = "0";
                    }
                    emergent_dynamics_nca_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2404.06406">
                    <papertitle>Emergent Dynamics in Neural Cellular Automata</papertitle>
                  </a>
                  <br>
                  <strong>Yitao Xu</strong>,
                  <a href="https://pajouheshgar.github.io/">Ehsan Pajouheshgar</a>,
                  <a href="https://people.epfl.ch/sabine.susstrunk">Sabine S√ºsstrunk</a>
                  <br>
                  <em>ALife</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2404.06406">arXiv</a>
                  /
                  <a href="https://arxiv.org/abs/2404.06406">code (Coming Soon!)</a>
                  <p></p>
                  <p>
                    We investigate the relationship between the NCA architecture and the emergent dynamics of the trained models.
                  </p>
                  <p>
                  </p>
                </td>
              </tr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="dynca_stop()" onmouseover="dynca_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dynca_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dynca.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/dynca.png' width="160">
              </div>
              <script type="text/javascript">
                function dynca_start() {
                  document.getElementById('dynca_image').style.opacity = "1";
                }

                function dynca_stop() {
                  document.getElementById('dynca_image').style.opacity = "0";
                }
                dynca_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.11417">
                <papertitle>DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular Automata</papertitle>
              </a>
              <br>
              <a href="https://pajouheshgar.github.io/">Ehsan Pajouheshgar*</a>,
              <strong>Yitao Xu*</strong>,
              <a href="https://sites.google.com/view/tong-zhang">Tong Zhang</a>,
							<a href="https://people.epfl.ch/sabine.susstrunk">Sabine S√ºsstrunk</a>
              <br>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://dynca.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2211.11417">arXiv</a>
              /
              <a href="https://github.com/IVRL/DyNCA">code</a>
              <p></p>
              <p>
                We propose Dynamic Neural Cellular Automata (DyNCA), a framework for real-time and controllable dynamic texture synthesis. Play with our <a href="https://dynca.github.io/">demo</a>!
                </p>
              <p>
              </p>
            </td>
          </tr>

					<tr onmouseout="ins_stop()" onmouseover="ins_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ins_image'>
                  <img src='images/ins_after.png' width="160"></div>
                <img src='images/ins_before.png' width="160">
              </div>
              <script type="text/javascript">
                function ins_start() {
                  document.getElementById('ins_image').style.opacity = "1";
                }
        
                function ins_stop() {
                  document.getElementById('ins_image').style.opacity = "0";
                }
                ins_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S0020025520308124">
                <papertitle>Understanding adversarial robustness via critical attacking route</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=XB6CydwAAAAJ&hl=en">Tianlin Li</a>, 
              <a href="https://liuaishan.github.io/">Aishan Liu</a>, 
              <a href="https://xlliu-beihang.github.io/">Xianglong Liu</a>, 
              <strong>Yitao Xu</strong>, 
              <a href="https://scholar.google.com.hk/citations?user=MaAiOikAAAAJ&hl=en-en">Chongzhi Zhang</a>,
              <a href="https://xiaofeixie.bitbucket.io/">Xiaofei Xie</a>
              <br>
              <em>Information Sciences</em>, 2021
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0020025520308124">paper</a>
              <p></p>
              <p>
                We believe that adversarial noises are amplified and propagated through the critical attacking route, identified by the proposed algorithm.
              </p>
            </td>
          </tr>		
				
          <tr onmouseout="eqa_stop()" onmouseover="eqa_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='eqa_image'><video  width=160 height=110 muted autoplay loop>
                <source src="images/eqa.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/eqa.jpg' width="160">
              </div>
              <script type="text/javascript">
                function eqa_start() {
                  document.getElementById('eqa_image').style.opacity = "1";
                }
        
                function eqa_stop() {
                  document.getElementById('eqa_image').style.opacity = "0";
                }
                eqa_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58520-4_8">
                <papertitle>Spatiotemporal Attacks for Embodied Agents</papertitle>
              </a>
              <br>
              <a href="https://liuaishan.github.io/">Aishan Liu</a>, 
              <a href="https://scholar.google.com.hk/citations?user=qXaEfxIAAAAJ&hl=en-en">Tairan Huang</a>,
              <a href="https://xlliu-beihang.github.io/">Xianglong Liu</a>, 
              <strong>Yitao Xu</strong>, 
              <a href="https://vickyfox.github.io/">Yuqing Ma</a>, 
              <a href="https://jungyhuk.github.io/">Xinyun Chen</a>, 
              <a href="https://www.dcs.bbk.ac.uk/~sjmaybank/">Steve Maybank</a>, 
              <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a>
              <br>
              <em>ECCV</em>, 2020
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58520-4_8">paper</a>
              <p></p>
              <p>
                We take the first step to study adversarial attacks for embodied agents. We generate spatiotemporal perturbations to form 3D adversarial examples, exploiting the
                interaction history in both the temporal and spatial dimensions.
                </p>
              </p>
            </td>
          </tr>
        
          <tr onmouseout="sns_stop()" onmouseover="sns_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sns_image'>
                  <img src='images/sns_after.png' width="160"></div>
                <img src='images/sns_before.png' width="160">
              </div>
              <script type="text/javascript">
                function sns_start() {
                  document.getElementById('sns_image').style.opacity = "1";
                }
          
                function sns_stop() {
                  document.getElementById('sns_image').style.opacity = "0";
                }
                sns_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9286885">
                <papertitle>Interpreting and Improving Adversarial Robustness of Deep Neural Networks with Neuron Sensitivity</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com.hk/citations?user=MaAiOikAAAAJ&hl=en-en">Chongzhi Zhang</a>,
              <a href="https://liuaishan.github.io/">Aishan Liu</a>, 
              <a href="https://xlliu-beihang.github.io/">Xianglong Liu</a>, 
              <strong>Yitao Xu</strong>, 
              <a href="https://ieeexplore.ieee.org/author/37088592575">Hang Yu</a>, 
              <a href="https://vickyfox.github.io/">Yuqing Ma</a>, 
              <a href="https://scholar.google.com/citations?user=XB6CydwAAAAJ&hl=en">Tianlin Li</a>
              <br>
              <em>IEEE Transactions on Image Processing</em>, 2020
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9286885">paper</a>
              <p></p>
              <p>
                We explain adversarial robustness for deep models from a new perspective of neuron sensitivity which is measured by neuron behavior variation intensity against benign and adversarial examples.
              </p>
            </td>
          </tr>		

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Design</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
